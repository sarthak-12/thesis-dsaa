{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f63978e-1241-442f-95c5-241ed2f5220d",
   "metadata": {},
   "source": [
    "# 1. Relevant Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2979364c-c4e9-484b-b95b-b56f96218624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c3dd1-e063-4873-acc0-c6fc50ccbab6",
   "metadata": {},
   "source": [
    "# 2. Initialize RoBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c96bba6-9b74-47c7-8bb3-6ab1110b29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnnotator:\n",
    "    def __init__(self, model_name='cardiffnlp/twitter-roberta-base-sentiment-latest'):\n",
    "        \"\"\"\n",
    "        Initializes the SentimentAnnotator with the specified model.\n",
    "        Utilizes Apple's MPS backend if available.\n",
    "        \"\"\"\n",
    "        self.device = self._get_device()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.model.to(self.device)\n",
    "        self.pipeline = TextClassificationPipeline(\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=self.device.index if self.device.type != 'cpu' else -1,\n",
    "            top_k=None,  # Return scores for all labels\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "    def _get_device(self):\n",
    "        \"\"\"\n",
    "        Determines the appropriate device to use (MPS if available, else CPU).\n",
    "        \"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device('mps')\n",
    "            print(\"Using Apple's MPS backend.\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print(\"MPS backend not available. Using CPU.\")\n",
    "        return device\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses the input text by cleaning and normalizing it.\n",
    "        \"\"\"\n",
    "        # Ensure required NLTK data is downloaded\n",
    "        nltk.download('stopwords', quiet=True)\n",
    "    \n",
    "        # Convert to string and strip leading/trailing whitespace\n",
    "        text = str(text).strip()\n",
    "    \n",
    "        # Handle missing or empty text\n",
    "        if not text:\n",
    "            return ''\n",
    "    \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def annotate(self, texts):\n",
    "        \"\"\"\n",
    "        Annotates a list of texts with sentiment scores.\n",
    "        \"\"\"\n",
    "        # Preprocess texts\n",
    "        preprocessed_texts = [self.preprocess_text(text) for text in texts]\n",
    "\n",
    "        # Run the pipeline\n",
    "        annotations = self.pipeline(preprocessed_texts)\n",
    "        return annotations\n",
    "\n",
    "    def annotate_dataframe(self, df, text_column, output_column='sentiment_score'):\n",
    "        texts = df[text_column].tolist()\n",
    "        annotations = self.annotate(texts)\n",
    "    \n",
    "        # Extract sentiment scores\n",
    "        scores = []\n",
    "        for annotation in annotations:\n",
    "            # Convert list of dicts to a dict for easier access\n",
    "            score_dict = {item['label']: item['score'] for item in annotation}\n",
    "    \n",
    "            # Correct label mapping for Twitter RoBERTa model\n",
    "            negative_score = score_dict.get('negative', 0)  # 'negative' label for negative sentiment\n",
    "            neutral_score = score_dict.get('neutral', 0)    # 'neutral' label for neutral sentiment\n",
    "            positive_score = score_dict.get('positive', 0)  # 'positive' label for positive sentiment\n",
    "    \n",
    "            # Calculate sentiment score considering neutral values\n",
    "            sentiment_score = (positive_score - negative_score) * (1 - neutral_score)\n",
    "            \n",
    "            # Format the score to two decimal places without rounding\n",
    "            # If sentiment_score is close to zero, set it explicitly to \"0.00\" to avoid \"-0.00\"\n",
    "            if abs(sentiment_score) < 0.005:\n",
    "                formatted_score = \"0.00\"\n",
    "            else:\n",
    "                formatted_score = f\"{sentiment_score:.2f}\"\n",
    "    \n",
    "            scores.append(formatted_score)\n",
    "\n",
    "        # Add the formatted sentiment scores to the DataFrame\n",
    "        df[output_column] = scores\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759633b0-3e74-4a69-9ca2-0026fa14d119",
   "metadata": {},
   "source": [
    "# 3. Annotation for different datsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a5285-29d1-449b-820a-d5682e50fd8d",
   "metadata": {},
   "source": [
    "## a. MRK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8c5b90-ab86-4f06-ab18-ab4bcc36e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple's MPS backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title sentiment_score\n",
      "0     Shares of several healthcare companies are tra...           -0.31\n",
      "1     Johnson & Johnson To Start Coronavirus Vaccine...            0.01\n",
      "2     The Daily Biotech Pulse: Keytruda Setback For ...           -0.38\n",
      "3     Merck Announces That The Phase 3 KEYNOTE-361 T...            0.00\n",
      "4     The Week Ahead In Biotech: Viela FDA Decision,...            0.01\n",
      "...                                                 ...             ...\n",
      "3329  BenchmarkJournal.com Free Analyst Review for A...            0.00\n",
      "3330  Trends in the U.K. and Irish Pharmaceutical an...            0.00\n",
      "3331  ParagonReport.com Complimentary Market Update ...            0.02\n",
      "3332  ParagonReport.com Complimentary Market Update ...            0.01\n",
      "3333  Wall Street News Alert:  Stocks This Morning: ...            0.01\n",
      "\n",
      "[3334 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Read the MRK_text.csv file\n",
    "    df = pd.read_csv('../dataset_final/Daily_Financial_News/MRK/MRK_text.csv')\n",
    "\n",
    "    # Initialize the annotator\n",
    "    annotator = SentimentAnnotator()\n",
    "\n",
    "    # Annotate the DataFrame using the 'title' column\n",
    "    annotated_df = annotator.annotate_dataframe(df, text_column='title', output_column='sentiment_score')\n",
    "\n",
    "    # Display the results\n",
    "    print(annotated_df[['title', 'sentiment_score']])\n",
    "\n",
    "    # Optionally, save the annotated DataFrame to a new CSV file\n",
    "    annotated_df.to_csv('../dataset_final/Daily_Financial_News/MRK/MRK_text_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a1a94-6bcb-464e-a2f6-8ddaab7e13c6",
   "metadata": {},
   "source": [
    "## b. MS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c20a593c-e93b-40ac-a84f-00ed5498cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple's MPS backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title sentiment_score\n",
      "0          Price Over Earnings Overview: Morgan Stanley            0.00\n",
      "1     Shares of several financial service companies ...           -0.22\n",
      "2     Goldman Sachs Employees Returning To Their Des...            0.01\n",
      "3     Shares of several financial services companies...            0.00\n",
      "4     Morgan Stanley CEO James Gorman Says Markets B...            0.04\n",
      "...                                                 ...             ...\n",
      "3237  4Q Profit For Morgan Stanley (MS) After Huge L...           -0.49\n",
      "3238  U.S Futures Slip Despite Optimism in the Econo...           -0.05\n",
      "3239  Company News for January 20, 2010 - Corporate ...            0.00\n",
      "3240  Top 5 Stocks To Focus On Today (MS, BAC, MTB, ...            0.02\n",
      "3241                 Banks Paid A TARP Premium (GS, MS)            0.00\n",
      "\n",
      "[3242 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Read the MS_text.csv file\n",
    "    df = pd.read_csv('../dataset_final/Daily_Financial_News/MS/MS_text.csv')\n",
    "\n",
    "    # Initialize the annotator\n",
    "    annotator = SentimentAnnotator()\n",
    "\n",
    "    # Annotate the DataFrame using the 'title' column\n",
    "    annotated_df = annotator.annotate_dataframe(df, text_column='title', output_column='sentiment_score')\n",
    "\n",
    "    # Display the results\n",
    "    print(annotated_df[['title', 'sentiment_score']])\n",
    "\n",
    "    # Optionally, save the annotated DataFrame to a new CSV file\n",
    "    annotated_df.to_csv('../dataset_final/Daily_Financial_News/MS/MS_text_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f67bea-5866-4f1e-b7ba-e9a348d9e55d",
   "metadata": {},
   "source": [
    "## c. MU dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22118230-5227-4398-aabf-29c34c512448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple's MPS backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title sentiment_score\n",
      "0     Hearing Wedbush Downgrades Micron On Valuation...           -0.06\n",
      "1     Many Smartphones Expected to Come with 256GB o...            0.10\n",
      "2     Shares of several companies in the broader tec...            0.59\n",
      "3     Shares of several technology companies are tra...            0.62\n",
      "4     Micron Launches Robot Design Challenge to Acce...            0.01\n",
      "...                                                 ...             ...\n",
      "3139  CEOWORLD Most Actives Technology Stocks by vol...            0.00\n",
      "3140  CEOWORLD Technology Stocks Watch on 4/27/11 (T...            0.03\n",
      "3141  Hot Stocks to Buy on 4/25/11 and April 26, 201...            0.01\n",
      "3142                   Earnings Preview: Sandisk (SNDK)            0.01\n",
      "3143  Benzinga's Top ETF Decliners, April 20th (SOXS...            0.01\n",
      "\n",
      "[3144 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Read the MU_text.csv file\n",
    "    df = pd.read_csv('../dataset_final/Daily_Financial_News/MU/MU_text.csv')\n",
    "\n",
    "    # Initialize the annotator\n",
    "    annotator = SentimentAnnotator()\n",
    "\n",
    "    # Annotate the DataFrame using the 'title' column\n",
    "    annotated_df = annotator.annotate_dataframe(df, text_column='title', output_column='sentiment_score')\n",
    "\n",
    "    # Display the results\n",
    "    print(annotated_df[['title', 'sentiment_score']])\n",
    "\n",
    "    # Optionally, save the annotated DataFrame to a new CSV file\n",
    "    annotated_df.to_csv('../dataset_final/Daily_Financial_News/MU/MU_text_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa757f-55ff-473c-8b2a-3677366fb696",
   "metadata": {},
   "source": [
    "## d. QQQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9812f056-5d60-4cb2-ad4f-115c0fc2430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple's MPS backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title sentiment_score\n",
      "0                   Afternoon Market Stats in 5 Minutes            0.01\n",
      "1                     Morning Market Stats in 5 Minutes            0.01\n",
      "2                   Afternoon Market Stats in 5 Minutes            0.01\n",
      "3     Cramer: NASDAQ Rebound Makes Sense As It Bette...            0.59\n",
      "4                     Morning Market Stats in 5 Minutes            0.01\n",
      "...                                                 ...             ...\n",
      "3095  Stocks Grind Higher On Wednesday (SPY, QQQQ, G...            0.04\n",
      "3096    Doug Kass Shorting Broader ETFs (IWM, SPY, QQQ)           -0.01\n",
      "3097    Reminder: QQQQ Changes To QQQ Today (QQQQ, QQQ)            0.00\n",
      "3098  PowerShares QQQ Ticker to Change from ‘QQQQ' t...            0.00\n",
      "3099  ETFs To Watch March 17, 2011 (CZI, EZJ, TMF, VNM)            0.00\n",
      "\n",
      "[3100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Read the QQQ_text.csv file\n",
    "    df = pd.read_csv('../dataset_final/Daily_Financial_News/QQQ/QQQ_text.csv')\n",
    "\n",
    "    # Initialize the annotator\n",
    "    annotator = SentimentAnnotator()\n",
    "\n",
    "    # Annotate the DataFrame using the 'title' column\n",
    "    annotated_df = annotator.annotate_dataframe(df, text_column='title', output_column='sentiment_score')\n",
    "\n",
    "    # Display the results\n",
    "    print(annotated_df[['title', 'sentiment_score']])\n",
    "\n",
    "    # Optionally, save the annotated DataFrame to a new CSV file\n",
    "    annotated_df.to_csv('../dataset_final/Daily_Financial_News/QQQ/QQQ_text_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb2df3-53f3-47bc-b4b9-a479417e4e40",
   "metadata": {},
   "source": [
    "## e. NVDA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ddcb0e-537f-44e6-8541-5f66ab9ea9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple's MPS backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title sentiment_score\n",
      "0     Shares of several technology companies are tra...            0.04\n",
      "1                   Afternoon Market Stats in 5 Minutes            0.01\n",
      "2                     Morning Market Stats in 5 Minutes            0.01\n",
      "3     Shares of several technology companies are tra...            0.37\n",
      "4                   Afternoon Market Stats in 5 Minutes            0.01\n",
      "...                                                 ...             ...\n",
      "3128  J.P. Morgan Upgrades NVIDIA Corporation To Neu...            0.01\n",
      "3129       JP Morgan Upgrades NVIDIA To Neutral, $21 PT            0.01\n",
      "3130  Goldman Sachs Gives Color On Semiconductors (N...            0.01\n",
      "3131  Auriga Still Not Sure Where Reality Lies For N...           -0.29\n",
      "3132                        Nvidia Goes Negative (NVDA)           -0.04\n",
      "\n",
      "[3133 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Read the NVDA_text.csv file\n",
    "    df = pd.read_csv('../dataset_final/Daily_Financial_News/NVDA/NVDA_text.csv')\n",
    "\n",
    "    # Initialize the annotator\n",
    "    annotator = SentimentAnnotator()\n",
    "\n",
    "    # Annotate the DataFrame using the 'title' column\n",
    "    annotated_df = annotator.annotate_dataframe(df, text_column='title', output_column='sentiment_score')\n",
    "\n",
    "    # Display the results\n",
    "    print(annotated_df[['title', 'sentiment_score']])\n",
    "\n",
    "    # Optionally, save the annotated DataFrame to a new CSV file\n",
    "    annotated_df.to_csv('../dataset_final/Daily_Financial_News/NVDA/NVDA_text_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9b97a-724f-498a-8d27-1c07e7a86664",
   "metadata": {},
   "source": [
    "# FinSen Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ebcd78a-0aa9-4d60-a511-3c6ef0dc938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple's MPS backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Content sentiment_score\n",
      "0      TSX Slightly Down, Books Weekly GainsUnited St...            0.13\n",
      "1      UnitedHealth Hits 4-week HighUnited States sto...            0.62\n",
      "2      Cisco Systems Hits 4-week LowUnited States sto...           -0.43\n",
      "3      AT&T Hits All-time LowUnited States stocksAT&T...           -0.28\n",
      "4      Microsoft Hits 4-week HighUnited States stocks...            0.60\n",
      "...                                                  ...             ...\n",
      "15529  United States GDP Rises 0.6 percent in the fir...            0.02\n",
      "15530  Consumer Price Index 2.6 percent higher than i...            0.00\n",
      "15531  U.S. Federal Reserve Kept Rates Unchanged at 5...           -0.01\n",
      "15532  Trade Deficit Increases in March 2007United St...            0.00\n",
      "15533  Blackstone boosts IPO after Beijing takes $3bn...            0.03\n",
      "\n",
      "[15534 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Read the FinSen_text.csv file\n",
    "    df = pd.read_csv('../dataset_final/FinSen_S&P500/FinSen_text.csv')\n",
    "\n",
    "    # Initialize the annotator\n",
    "    annotator = SentimentAnnotator()\n",
    "\n",
    "    # Annotate the DataFrame using the 'Content' column\n",
    "    annotated_df = annotator.annotate_dataframe(df, text_column='Content', output_column='sentiment_score')\n",
    "\n",
    "    # Display the results\n",
    "    print(annotated_df[['Content', 'sentiment_score']])\n",
    "\n",
    "    # Optionally, save the annotated DataFrame to a new CSV file\n",
    "    annotated_df.to_csv('../dataset_final/FinSen_S&P500/FinSen_text_annotated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abeb79d-432f-473d-9acc-70595c74de7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
