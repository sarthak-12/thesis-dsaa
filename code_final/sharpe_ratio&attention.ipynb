{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5b968c-2b07-4f21-baf9-1ff371c60298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Excess Return: 0.0008174603174603175\n",
      "Standard Deviation of Excess Return: 0.0017053337694733315\n",
      "Annualized Sharpe Ratio: 7.609525168783332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example daily returns (in decimal form) for a sample strategy\n",
    "daily_returns = np.array([0.002, -0.001, 0.003, 0.0005, 0.0025, -0.002, 0.001])\n",
    "\n",
    "# Assume an annual risk-free rate of 2% and convert it to a daily rate\n",
    "risk_free_rate_annual = 0.01  \n",
    "risk_free_rate_daily = risk_free_rate_annual / 252  # ~252 trading days in a year\n",
    "\n",
    "# Calculate excess returns by subtracting the risk-free rate from the daily returns\n",
    "excess_returns = daily_returns - risk_free_rate_daily\n",
    "\n",
    "# Compute the mean and standard deviation of the excess returns\n",
    "mean_excess = np.mean(excess_returns)\n",
    "std_excess = np.std(excess_returns)\n",
    "\n",
    "# Calculate the daily Sharpe Ratio and annualize it (multiply by sqrt(252))\n",
    "sharpe_ratio = (mean_excess / std_excess) * np.sqrt(252)\n",
    "\n",
    "print(\"Mean Excess Return:\", mean_excess)\n",
    "print(\"Standard Deviation of Excess Return:\", std_excess)\n",
    "print(\"Annualized Sharpe Ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d007f78f-9d8a-46f9-aed9-f4663c1a3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Return over period: 0.007510468426500161\n",
      "Annualized Return: 0.30913496910123484\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example daily returns in decimal form (e.g., 0.01 for 1% return)\n",
    "daily_returns = np.array([0.001, -0.002, 0.003, 0.0005, 0.002, -0.001, 0.004])\n",
    "\n",
    "# Calculate the cumulative return over the period\n",
    "# (Product of (1 + daily return) for each day) - 1 gives total return\n",
    "cumulative_return = np.prod(1 + daily_returns) - 1\n",
    "\n",
    "# Number of trading days in the period\n",
    "n = len(daily_returns)\n",
    "\n",
    "# Annualize the cumulative return:\n",
    "# Formula: Annualized Return = (1 + cumulative_return)^(252/n) - 1\n",
    "annualized_return = (1 + cumulative_return) ** (252 / n) - 1\n",
    "\n",
    "print(\"Cumulative Return over period:\", cumulative_return)\n",
    "print(\"Annualized Return:\", annualized_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55167e5-5b6d-4d89-bae4-092c787b55e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Sentiment  Actual_Label  Predicted_Label  \\\n",
      "0  2023-01-01    100        0.8             1                1   \n",
      "1  2023-01-02    102       -0.5             1                0   \n",
      "2  2023-01-03     98        0.2             0                0   \n",
      "3  2023-01-04    101       -0.3             0                1   \n",
      "4  2023-01-05    103        0.6             1                1   \n",
      "\n",
      "   Predicted_Probability  Actual_Return  \n",
      "0                    0.9          0.020  \n",
      "1                    0.4         -0.010  \n",
      "2                    0.3         -0.030  \n",
      "3                    0.6          0.015  \n",
      "4                    0.8          0.025  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Mock data\n",
    "data = {\n",
    "    \"Date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\", \"2023-01-05\"],\n",
    "    \"Close\": [100, 102, 98, 101, 103],\n",
    "    \"Sentiment\": [0.8, -0.5, 0.2, -0.3, 0.6],\n",
    "    \"Actual_Label\": [1, 1, 0, 0, 1],  # 1=Up, 0=Down\n",
    "    \"Predicted_Label\": [1, 0, 0, 1, 1],  # Model predictions\n",
    "    \"Predicted_Probability\": [0.9, 0.4, 0.3, 0.6, 0.8],  # Confidence scores\n",
    "    \"Actual_Return\": [0.02, -0.01, -0.03, 0.015, 0.025]  # Daily returns\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f458e345-41e8-40df-b8c1-a1b6eb0476c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio: -8.07\n"
     ]
    }
   ],
   "source": [
    "# Calculate strategy returns (1% transaction cost assumed)\n",
    "df[\"Strategy_Return\"] = np.where(\n",
    "    df[\"Predicted_Label\"] == df[\"Actual_Label\"],\n",
    "    df[\"Actual_Return\"] - 0.01,  # Win with cost\n",
    "    -abs(df[\"Actual_Return\"]) - 0.01  # Loss with cost\n",
    ")\n",
    "\n",
    "# Annualized Sharpe Ratio\n",
    "returns = df[\"Strategy_Return\"]\n",
    "sharpe_ratio = (returns.mean() * 252) / (returns.std() * np.sqrt(252))\n",
    "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81be6697-8a56-4ab5-ba58-45923865468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit Factor: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Calculate profit factor\n",
    "gross_profit = df[df[\"Strategy_Return\"] > 0][\"Strategy_Return\"].sum()\n",
    "gross_loss = abs(df[df[\"Strategy_Return\"] < 0][\"Strategy_Return\"].sum())\n",
    "profit_factor = gross_profit / gross_loss\n",
    "print(f\"Profit Factor: {profit_factor:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0821ba00-497b-41c6-abc3-174281d7109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Drawdown: -8.27%\n"
     ]
    }
   ],
   "source": [
    "# Calculate cumulative returns\n",
    "cumulative_returns = (1 + returns).cumprod()\n",
    "peak = cumulative_returns.expanding().max()\n",
    "drawdown = (cumulative_returns - peak) / peak\n",
    "max_drawdown = drawdown.min()\n",
    "print(f\"Max Drawdown: {max_drawdown:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4cafd79-1a4e-4e0b-8014-b0ff5735dd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Weighted Return: 0.0340\n"
     ]
    }
   ],
   "source": [
    "# Calculate weighted returns\n",
    "df[\"Weighted_Return\"] = df[\"Predicted_Probability\"] * df[\"Actual_Return\"]\n",
    "total_weighted_return = df[\"Weighted_Return\"].sum()\n",
    "print(f\"Precision-Weighted Return: {total_weighted_return:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61808754-cdeb-4cce-9593-432fb8bf7b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Economic Confusion Matrix ($):\n",
      "-----------------------------\n",
      "|          | Predicted Up | Predicted Down |\n",
      "|----------|--------------|-----------------|\n",
      "| Actual Up| $450    | $-100 (Missed)|\n",
      "| Actual Dn| $150 (Loss)| $300 (Saved) |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate monetary impact (assuming $10,000 position size)\n",
    "position_size = 10000\n",
    "\n",
    "tp = df[(df[\"Predicted_Label\"] == 1) & (df[\"Actual_Label\"] == 1)][\"Actual_Return\"].sum() * position_size\n",
    "fp = df[(df[\"Predicted_Label\"] == 1) & (df[\"Actual_Label\"] == 0)][\"Actual_Return\"].sum() * position_size\n",
    "fn = df[(df[\"Predicted_Label\"] == 0) & (df[\"Actual_Label\"] == 1)][\"Actual_Return\"].sum() * position_size\n",
    "tn = abs(df[(df[\"Predicted_Label\"] == 0) & (df[\"Actual_Label\"] == 0)][\"Actual_Return\"].sum()) * position_size\n",
    "\n",
    "print(f\"\"\"\n",
    "Economic Confusion Matrix ($):\n",
    "-----------------------------\n",
    "|          | Predicted Up | Predicted Down |\n",
    "|----------|--------------|-----------------|\n",
    "| Actual Up| ${tp:,.0f}    | ${fn:,.0f} (Missed)|\n",
    "| Actual Dn| ${fp:,.0f} (Loss)| ${tn:,.0f} (Saved) |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "415d8a76-a570-4dd6-82b9-693599b249aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turnover-Adjusted Win Rate: 49.40%\n"
     ]
    }
   ],
   "source": [
    "def adjusted_win_rate(df, commission=0.0001):\n",
    "    trades = df[df[\"Predicted_Label\"] != 0]  # Count only active trades\n",
    "    gross_profit = trades[trades[\"Strategy_Return\"] > 0][\"Strategy_Return\"].sum()\n",
    "    costs = len(trades) * commission\n",
    "    return (gross_profit - costs) / trades[\"Strategy_Return\"].abs().sum()\n",
    "\n",
    "win_rate = adjusted_win_rate(df)\n",
    "print(f\"Turnover-Adjusted Win Rate: {win_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ede5a6b-4d55-4ca7-82f9-d782c00b61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha vs Benchmark: -0.0160\n"
     ]
    }
   ],
   "source": [
    "# Assume benchmark returns (e.g., S&P 500)\n",
    "benchmark_returns = np.array([0.01, 0.005, -0.02, 0.015, 0.01])  # Example values\n",
    "alpha = returns.mean() - benchmark_returns.mean()\n",
    "print(f\"Alpha vs Benchmark: {alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7440e1-3a2c-4e5e-9b72-16b5a0d86a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3964fa0f-2368-4603-b6b0-16af3791fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text indices: tensor([[0, 1, 2, 3, 4, 5]])\n",
      "Numeric tensor: tensor([[0.0500, 1.2000, 0.3000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example text (news headline) and numeric features for a single data point\n",
    "text = \"stocks rally after record earnings report\"\n",
    "# A very simple tokenization for illustration:\n",
    "vocab = {\"stocks\": 0, \"rally\": 1, \"after\": 2, \"record\": 3, \"earnings\": 4, \"report\": 5}\n",
    "text_tokens = [vocab[word] for word in text.split()]\n",
    "# Numeric features: e.g., [daily_percent_change, volume_zscore, volatility]\n",
    "numeric_features = [0.05, 1.2, 0.3]  # dummy values\n",
    "\n",
    "# Convert to tensors\n",
    "text_indices = torch.tensor([text_tokens])          # shape: (batch=1, seq_len)\n",
    "numeric_tensor = torch.tensor([numeric_features])   # shape: (batch=1, num_features)\n",
    "print(\"Text indices:\", text_indices)\n",
    "print(\"Numeric tensor:\", numeric_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b501a284-7b93-48c8-9443-66b9e92416bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embedding shape: torch.Size([1, 6, 16])\n",
      "Numeric embedding shape: torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embed_dim = 16\n",
    "vocab_size = len(vocab)\n",
    "num_features = numeric_tensor.shape[1]\n",
    "\n",
    "# Embedding layer for text tokens and linear layer for numeric features\n",
    "text_embed_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "numeric_embed_layer = nn.Linear(num_features, embed_dim)\n",
    "\n",
    "# Apply the embedding layers to the inputs\n",
    "text_embedded = text_embed_layer(text_indices)      # shape: (1, seq_len, embed_dim)\n",
    "numeric_embedded = numeric_embed_layer(numeric_tensor)  # shape: (1, embed_dim)\n",
    "\n",
    "print(\"Text embedding shape:\", text_embedded.shape)\n",
    "print(\"Numeric embedding shape:\", numeric_embedded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b66b0fc-9d74-4226-a58c-d1f6d88b6445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text sequence shape (L,N,E): torch.Size([6, 1, 16])\n",
      "Numeric sequence shape (L,N,E): torch.Size([1, 1, 16])\n"
     ]
    }
   ],
   "source": [
    "# Transpose text to (seq_len, batch, embed_dim)\n",
    "text_embed_seq = text_embedded.permute(1, 0, 2)        # shape: (seq_len, 1, 16)\n",
    "# Add a seq_len dimension of 1 to numeric embed and transpose to (1, batch, embed_dim)\n",
    "numeric_embed_seq = numeric_embedded.unsqueeze(0).permute(0, 1, 2)  # shape: (1, 1, 16)\n",
    "\n",
    "print(\"Text sequence shape (L,N,E):\", text_embed_seq.shape)\n",
    "print(\"Numeric sequence shape (L,N,E):\", numeric_embed_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103e527c-fda6-47fe-9314-5eee0d7fbe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attended numeric shape: torch.Size([1, 1, 16])\n",
      "Attention weights shape: torch.Size([1, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "# Initialize a MultiheadAttention module\n",
    "d_model = embed_dim  # embedding dimension\n",
    "num_heads = 1        # single-head attention for simplicity\n",
    "cross_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=False)\n",
    "\n",
    "# Perform cross-modal attention: numeric queries attend to textual keys/values\n",
    "attended_numeric, attn_weights = cross_attn(query=numeric_embed_seq, key=text_embed_seq, value=text_embed_seq)\n",
    "\n",
    "print(\"Attended numeric shape:\", attended_numeric.shape)\n",
    "print(\"Attention weights shape:\", attn_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac1f55a-eafa-48ea-9156-eecb03af80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused feature shape: torch.Size([1, 32])\n",
      "Output prediction shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Combine the attended numeric embedding with original numeric embedding\n",
    "attended_numeric_vec = attended_numeric.permute(1, 0, 2).reshape(1, -1)  # (1, 16)\n",
    "original_numeric_vec = numeric_embedded  # (1, 16), already batch x embed\n",
    "fused_vector = torch.cat([attended_numeric_vec, original_numeric_vec], dim=1)  # shape: (1, 32)\n",
    "\n",
    "# A simple linear classifier on top of the fused features\n",
    "output_layer = nn.Linear(32, 2)  # e.g., two output classes (rise vs fall)\n",
    "prediction = output_layer(fused_vector)\n",
    "\n",
    "print(\"Fused feature shape:\", fused_vector.shape)\n",
    "print(\"Output prediction shape:\", prediction.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b99341-1395-489c-ac49-b6aab534b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example dimensions\n",
    "batch_size = 32\n",
    "num_numeric_features = 10\n",
    "text_seq_len = 50\n",
    "embed_dim = 128\n",
    "\n",
    "# Dummy inputs (replace with real data in practice)\n",
    "numeric_input = torch.randn(batch_size, num_numeric_features)       # [batch_size, num_numeric_features]\n",
    "text_embeddings = torch.randn(text_seq_len, batch_size, embed_dim)  # [text_seq_len, batch_size, embed_dim]\n",
    "\n",
    "# Linear projection for numeric features to match embed_dim\n",
    "numeric_proj = nn.Linear(num_numeric_features, embed_dim)\n",
    "numeric_embed = F.relu(numeric_proj(numeric_input))      # [batch_size, embed_dim]\n",
    "numeric_query = numeric_embed.unsqueeze(0)               # [1, batch_size, embed_dim] -> query sequence of length 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec83a108-d2ef-450c-824f-baed825da75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multi-head attention (e.g., 4 heads)\n",
    "num_heads = 4\n",
    "cross_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "\n",
    "# Perform cross-attention: Query=numeric (1 x B x D), Key=Value=text (T x B x D)\n",
    "attn_output, attn_weights = cross_attn(query=numeric_query, key=text_embeddings, value=text_embeddings)\n",
    "# attn_output: [1, batch_size, embed_dim]\n",
    "# attn_weights: [batch_size, 1, text_seq_len] (attention scores over text tokens for each query element)\n",
    "\n",
    "# Remove the sequence length dimension (since it's 1) to get fused feature vector per sample\n",
    "fused_vector = attn_output.squeeze(0)  # [batch_size, embed_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53db2c3d-27ca-4bca-a064-28f795caca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token:  Paris\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Load ModernBERT (Base version)\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id)\n",
    "\n",
    "# Input text with a masked token\n",
    "text = \"The capital of France is [MASK].\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Get model outputs\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Locate the position of the [MASK] token\n",
    "mask_index = inputs[\"input_ids\"][0].tolist().index(tokenizer.mask_token_id)\n",
    "\n",
    "# Predict the masked token\n",
    "predicted_id = outputs.logits[0, mask_index].argmax(axis=-1)\n",
    "predicted_token = tokenizer.decode(predicted_id)\n",
    "\n",
    "print(\"Predicted token:\", predicted_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac787b2-92ea-48a7-b705-f84ccfa783bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
